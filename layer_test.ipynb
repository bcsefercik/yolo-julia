{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Activating\u001b[22m\u001b[39m environment at `~/Desktop/MSc/repos/yolo-julia/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "using CUDA\n",
    "using Statistics\n",
    "using Random\n",
    "using Test\n",
    "import Base: length, size, iterate, eltype, IteratorSize, IteratorEltype, haslength, @propagate_inbounds, repeat, rand, tail\n",
    "import .Iterators: cycle, Cycle, take\n",
    "using Plots; default(fmt=:png,ls=:auto)\n",
    "\n",
    "import Knet\n",
    "using Knet: deconv4, conv4, unpool, pool, mat, sigm, KnetArray, nll, zeroone, progress, adam!, sgd!, param, param0, dropout, relu, minibatch, Data\n",
    "import Knet: train!\n",
    "\n",
    "using MLDatasets: MNIST\n",
    "\n",
    "Pkg.activate(\"Project.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "xtrn, ytrn = MNIST.traindata(Float32); ytrn[ytrn.==0] .= 10;\n",
    "xtst, ytst = MNIST.testdata(Float32);  ytst[ytst.==0] .= 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 1, 1)\n",
      "Main.NN"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module NN.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".Chain\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Any,1}:\n",
       " Main.NN.Conv2d(P(Array{Float32,4}(5,5,1,1)), nothing, 1, 0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"nn.jl\")\n",
    "\n",
    "import .NN\n",
    "\n",
    "dtrn = minibatch(xtrn, ytrn, 200; xsize = (28,28,1,:), xtype=Knet.atype(), shuffle=true);\n",
    "dtst = minibatch(xtst, ytst, 200; xsize = (28,28,1,:), xtype=Knet.atype());\n",
    "x, y = first(dtst)\n",
    "\n",
    "\n",
    "dl2 = NN.Conv2d(5, 1, 1)\n",
    "println(size(dl2.w))\n",
    "cc = NN.Chain()\n",
    "println(typeof(cc))\n",
    "push!(cc.layers, dl2)\n",
    "cc.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module NN.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Any[Main.NN.Chain(Any[Main.NN.Conv2d(P(Array{Float32,4}(3,3,3,32)), nothing, 1, 1), Main.NN.BatchNorm2d(Knet.Ops20.BNMoments(0.03, nothing, nothing, zeros, ones), Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.0001), Main.NN.LeakyReLU(Float32[0.1])]), Main.NN.Chain(Any[Main.NN.Conv2d(P(Array{Float32,4}(3,3,32,64)), nothing, 2, 1), Main.NN.BatchNorm2d(Knet.Ops20.BNMoments(0.03, nothing, nothing, zeros, ones), Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.0001), Main.NN.LeakyReLU(Float32[0.1])]), Main.NN.Chain(Any[Main.NN.Conv2d(P(Array{Float32,4}(1,1,64,32)), nothing, 1, 0), Main.NN.BatchNorm2d(Knet.Ops20.BNMoments(0.03, nothing, nothing, zeros, ones), Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.0001), Main.NN.LeakyReLU(Float32[0.1])]), Main.NN.Chain(Any[Main.NN.Conv2d(P(Array{Float32,4}(3,3,32,64)), nothing, 1, 1), Main.NN.BatchNorm2d(Knet.Ops20.BNMoments(0.03, nothing, nothing, zeros, ones), Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.0001), Main.NN.LeakyReLU(Float32[0.1])]), Main.NN.WeightedFeatureFusion([-3], 2), Main.NN.Chain(Any[Main.NN.Conv2d(P(Array{Float32,4}(3,3,64,128)), nothing, 2, 1), Main.NN.BatchNorm2d(Knet.Ops20.BNMoments(0.03, nothing, nothing, zeros, ones), Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.0001), Main.NN.LeakyReLU(Float32[0.1])]), Main.NN.Chain(Any[Main.NN.Conv2d(P(Array{Float32,4}(1,1,128,64)), nothing, 1, 0), Main.NN.BatchNorm2d(Knet.Ops20.BNMoments(0.03, nothing, nothing, zeros, ones), Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.0001), Main.NN.LeakyReLU(Float32[0.1])]), Main.NN.Chain(Any[Main.NN.Conv2d(P(Array{Float32,4}(3,3,64,128)), nothing, 1, 1), Main.NN.BatchNorm2d(Knet.Ops20.BNMoments(0.03, nothing, nothing, zeros, ones), Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.0001), Main.NN.LeakyReLU(Float32[0.1])]), Main.NN.WeightedFeatureFusion([-3], 2), Main.NN.Chain(Any[Main.NN.Conv2d(P(Array{Float32,4}(1,1,128,64)), nothing, 1, 0), Main.NN.BatchNorm2d(Knet.Ops20.BNMoments(0.03, nothing, nothing, zeros, ones), Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.0001), Main.NN.LeakyReLU(Float32[0.1])])  …  Main.NN.Chain(Any[Main.NN.Conv2d(P(Array{Float32,4}(1,1,512,128)), nothing, 1, 0), Main.NN.BatchNorm2d(Knet.Ops20.BNMoments(0.03, nothing, nothing, zeros, ones), Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.0001), Main.NN.LeakyReLU(Float32[0.1])]), Main.NN.Upsample2d(2, \"nearest\"), Main.NN.FeatureConcat([-1, 36], true), Main.NN.Chain(Any[Main.NN.Conv2d(P(Array{Float32,4}(1,1,384,128)), nothing, 1, 0), Main.NN.BatchNorm2d(Knet.Ops20.BNMoments(0.03, nothing, nothing, zeros, ones), Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.0001), Main.NN.LeakyReLU(Float32[0.1])]), Main.NN.Chain(Any[Main.NN.Conv2d(P(Array{Float32,4}(3,3,128,256)), nothing, 1, 1), Main.NN.BatchNorm2d(Knet.Ops20.BNMoments(0.03, nothing, nothing, zeros, ones), Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.0001), Main.NN.LeakyReLU(Float32[0.1])]), Main.NN.Chain(Any[Main.NN.Conv2d(P(Array{Float32,4}(1,1,256,128)), nothing, 1, 0), Main.NN.BatchNorm2d(Knet.Ops20.BNMoments(0.03, nothing, nothing, zeros, ones), Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.0001), Main.NN.LeakyReLU(Float32[0.1])]), Main.NN.Chain(Any[Main.NN.Conv2d(P(Array{Float32,4}(3,3,128,256)), nothing, 1, 1), Main.NN.BatchNorm2d(Knet.Ops20.BNMoments(0.03, nothing, nothing, zeros, ones), Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.0001), Main.NN.LeakyReLU(Float32[0.1])]), Main.NN.Chain(Any[Main.NN.Conv2d(P(Array{Float32,4}(1,1,256,128)), nothing, 1, 0), Main.NN.BatchNorm2d(Knet.Ops20.BNMoments(0.03, nothing, nothing, zeros, ones), Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.0001), Main.NN.LeakyReLU(Float32[0.1])]), Main.NN.Chain(Any[Main.NN.Conv2d(P(Array{Float32,4}(3,3,128,256)), nothing, 1, 1), Main.NN.BatchNorm2d(Knet.Ops20.BNMoments(0.03, nothing, nothing, zeros, ones), Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.0001), Main.NN.LeakyReLU(Float32[0.1])]), Main.NN.Chain(Any[Main.NN.Conv2d(P(Array{Float32,4}(1,1,256,255)), P(Array{Float32,4}(1,1,255,1)), 1, 0)])], Any[2, 6, 9, 13, 16, 19, 22, 25, 28, 31  …  72, 82, 80, 86, 62, 94, 92, 98, 37, 106])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"utils/parse_config.jl\")\n",
    "include(\"models.jl\")\n",
    "\n",
    "mdefs = parse_model_cfg(\"yolov3.cfg\")\n",
    "layers, routes = create_modules(mdefs, 416)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[2, 6, 9, 13, 16, 19, 22, 25, 28, 31, 34, 38, 41, 44, 47, 50, 53, 56, 59, 63, 66, 69, 72, 82, 80, 86, 62, 94, 92, 98, 37, 106]\n"
     ]
    }
   ],
   "source": [
    "println(routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module NN.\n"
     ]
    }
   ],
   "source": [
    "include(\"nn.jl\")\n",
    "\n",
    "import .NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "function dtype(); CUDA.functional() ? KnetArray{Float32} : Array{Float32}; end;\n",
    "\n",
    "# Define dense layer:\n",
    "struct Dense\n",
    "    w; b; f; p; \n",
    "    \n",
    "    function Dense(inputsize::Int, outputsize::Int, f=relu; \n",
    "            pdrop=0, atype=dtype())\n",
    "        \n",
    "        return new(\n",
    "            param(outputsize, inputsize; atype=atype),\n",
    "            param0(outputsize; atype=atype),\n",
    "            f,\n",
    "            pdrop\n",
    "        )\n",
    "    end\n",
    "end\n",
    "\n",
    "(d::Dense)(x) = d.f.(d.w * mat(dropout(x, d.p)) .+ d.b)\n",
    "\n",
    "\n",
    "# Define convolutional layer:\n",
    "struct Conv \n",
    "    w; b; f; p; \n",
    "    \n",
    "    function Conv(w1::Int, w2::Int, cx::Int, cy::Int, f=relu;\n",
    "            pdrop=0, atype=dtype())\n",
    "        \n",
    "        return new(\n",
    "            param(w1,w2,cx,cy; atype=atype), \n",
    "            param0(1,1,cy,1; atype=atype),\n",
    "            f,\n",
    "            pdrop\n",
    "        )\n",
    "    end\n",
    "end\n",
    "\n",
    "(c::Conv)(x) = c.f.(conv4(c.w, dropout(x, c.p)) .+ c.b)\n",
    "\n",
    "\n",
    "# Define chain of layers\n",
    "struct Chain\n",
    "    layers\n",
    "    Chain(layers...) = new(layers)\n",
    "end\n",
    "\n",
    "(c::Chain)(x) = (for l in c.layers; x = l(x); end; x)  # Forward pass\n",
    "\n",
    "# Loss and accuracy\n",
    "function (c::Chain)(x, y; accuracy::Bool=false)\n",
    "    y_pred = c(x)\n",
    "    \n",
    "    if accuracy\n",
    "        correct = 0.0\n",
    "        \n",
    "        for i=1:length(y)\n",
    "            correct += y[i] == findmax(y_pred[:, i]; dims=1)[2][1] ? 1.0 : 0.0\n",
    "        end\n",
    "        \n",
    "        return correct / length(y)\n",
    "    else\n",
    "        return nll(y_pred, y)\n",
    "    end\n",
    "end\n",
    "\n",
    "(c::Chain)(d::Data; accuracy::Bool=false) = mean(c(x,y; accuracy=accuracy) for (x,y) in d)  # Batch loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train! (generic function with 5 methods)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train!(model::NN.Chain, train_data::Data, test_data::Data;\n",
    "                  period::Int=4, iters::Int=100, lr=0.15, optimizer=sgd!)  # or optimizer=adam!\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    \n",
    "    for i in 0:period:iters\n",
    "        push!(train_loss, model(train_data))\n",
    "        push!(test_loss, model(test_data))\n",
    "    \n",
    "        push!(train_acc, model(train_data; accuracy=true))\n",
    "        push!(test_acc, model(test_data; accuracy=true))\n",
    "        \n",
    "        optimizer(model, take(cycle(train_data), period); lr=lr)\n",
    "        \n",
    "        \n",
    "            println(\"Iter: \", i)\n",
    "    end\n",
    "    \n",
    "    return 0:period:iters, train_loss, train_acc, test_loss, test_acc\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4]\n",
      "[1, 4, 4]\n",
      "[1, 4, 4, 4]\n",
      "Iter: 0\n",
      "Iter: 1\n",
      "Iter: 2\n",
      "Iter: 3\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "TaskFailedException:\nInterruptException:\nStacktrace:\n [1] ntuple(::NNlib.var\"#4#5\"{Tuple{Int64,Int64,Int64},Tuple{Int64,Int64,Int64},Tuple{Int64,Int64,Int64},NTuple{6,Int64},Tuple{Int64,Int64,Int64}}, ::Int64) at ./ntuple.jl:17\n [2] output_size at /home/bcs/.julia/packages/NNlib/E3YZL/src/dim_helpers/ConvDims.jl:120 [inlined]\n [3] im2col!(::SubArray{Float32,2,Array{Float32,3},Tuple{Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Int64},true}, ::SubArray{Float32,4,Array{Float32,5},Tuple{Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Int64},true}, ::NNlib.DenseConvDims{3,(3, 3, 1),1,4,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false}) at /home/bcs/.julia/packages/NNlib/E3YZL/src/impl/conv_im2col.jl:189\n [4] macro expansion at /home/bcs/.julia/packages/NNlib/E3YZL/src/impl/conv_im2col.jl:53 [inlined]\n [5] (::NNlib.var\"#406#threadsfor_fun#177\"{Array{Float32,3},Float32,Float32,Array{Float32,5},Array{Float32,5},Array{Float32,5},NNlib.DenseConvDims{3,(3, 3, 1),1,4,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false},Int64,Int64,Int64,UnitRange{Int64}})(::Bool) at ./threadingconstructs.jl:81\n [6] (::NNlib.var\"#406#threadsfor_fun#177\"{Array{Float32,3},Float32,Float32,Array{Float32,5},Array{Float32,5},Array{Float32,5},NNlib.DenseConvDims{3,(3, 3, 1),1,4,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false},Int64,Int64,Int64,UnitRange{Int64}})() at ./threadingconstructs.jl:48",
     "output_type": "error",
     "traceback": [
      "TaskFailedException:\nInterruptException:\nStacktrace:\n [1] ntuple(::NNlib.var\"#4#5\"{Tuple{Int64,Int64,Int64},Tuple{Int64,Int64,Int64},Tuple{Int64,Int64,Int64},NTuple{6,Int64},Tuple{Int64,Int64,Int64}}, ::Int64) at ./ntuple.jl:17\n [2] output_size at /home/bcs/.julia/packages/NNlib/E3YZL/src/dim_helpers/ConvDims.jl:120 [inlined]\n [3] im2col!(::SubArray{Float32,2,Array{Float32,3},Tuple{Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Int64},true}, ::SubArray{Float32,4,Array{Float32,5},Tuple{Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Base.Slice{Base.OneTo{Int64}},Int64},true}, ::NNlib.DenseConvDims{3,(3, 3, 1),1,4,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false}) at /home/bcs/.julia/packages/NNlib/E3YZL/src/impl/conv_im2col.jl:189\n [4] macro expansion at /home/bcs/.julia/packages/NNlib/E3YZL/src/impl/conv_im2col.jl:53 [inlined]\n [5] (::NNlib.var\"#406#threadsfor_fun#177\"{Array{Float32,3},Float32,Float32,Array{Float32,5},Array{Float32,5},Array{Float32,5},NNlib.DenseConvDims{3,(3, 3, 1),1,4,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false},Int64,Int64,Int64,UnitRange{Int64}})(::Bool) at ./threadingconstructs.jl:81\n [6] (::NNlib.var\"#406#threadsfor_fun#177\"{Array{Float32,3},Float32,Float32,Array{Float32,5},Array{Float32,5},Array{Float32,5},NNlib.DenseConvDims{3,(3, 3, 1),1,4,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false},Int64,Int64,Int64,UnitRange{Int64}})() at ./threadingconstructs.jl:48",
      "",
      "Stacktrace:",
      " [1] wait at ./task.jl:267 [inlined]",
      " [2] threading_run(::Function) at ./threadingconstructs.jl:34",
      " [3] macro expansion at ./threadingconstructs.jl:93 [inlined]",
      " [4] conv_im2col!(::Array{Float32,5}, ::Array{Float32,5}, ::Array{Float32,5}, ::NNlib.DenseConvDims{3,(3, 3, 1),1,4,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false}; col::Array{Float32,3}, alpha::Float32, beta::Float32) at /home/bcs/.julia/packages/NNlib/E3YZL/src/impl/conv_im2col.jl:49",
      " [5] conv_im2col! at /home/bcs/.julia/packages/NNlib/E3YZL/src/impl/conv_im2col.jl:30 [inlined]",
      " [6] #conv!#112 at /home/bcs/.julia/packages/NNlib/E3YZL/src/conv.jl:191 [inlined]",
      " [7] conv!(::Array{Float32,5}, ::Array{Float32,5}, ::Array{Float32,5}, ::NNlib.DenseConvDims{3,(3, 3, 1),1,4,(1, 1, 1),(1, 1, 1, 1, 0, 0),(1, 1, 1),false}) at /home/bcs/.julia/packages/NNlib/E3YZL/src/conv.jl:191",
      " [8] conv!(::Array{Float32,4}, ::Array{Float32,4}, ::Array{Float32,4}, ::NNlib.DenseConvDims{2,(3, 3),1,4,(1, 1),(1, 1, 1, 1),(1, 1),false}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/bcs/.julia/packages/NNlib/E3YZL/src/conv.jl:148",
      " [9] conv! at /home/bcs/.julia/packages/NNlib/E3YZL/src/conv.jl:148 [inlined]",
      " [10] conv(::Array{Float32,4}, ::Array{Float32,4}, ::NNlib.DenseConvDims{2,(3, 3),1,4,(1, 1),(1, 1, 1, 1),(1, 1),false}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/bcs/.julia/packages/NNlib/E3YZL/src/conv.jl:91",
      " [11] conv(::Array{Float32,4}, ::Array{Float32,4}, ::NNlib.DenseConvDims{2,(3, 3),1,4,(1, 1),(1, 1, 1, 1),(1, 1),false}) at /home/bcs/.julia/packages/NNlib/E3YZL/src/conv.jl:89",
      " [12] conv4(::Array{Float32,4}, ::Array{Float32,4}; padding::Int64, stride::Int64, dilation::Int64, mode::Int64, alpha::Int64, group::Int64) at /home/bcs/.julia/packages/Knet/LdQyF/src/ops20/conv.jl:40",
      " [13] forw(::Function, ::Param{Array{Float32,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol,Symbol},NamedTuple{(:stride, :padding),Tuple{Int64,Int64}}}) at /home/bcs/.julia/packages/AutoGrad/VFrAv/src/core.jl:66",
      " [14] #conv4#28 at ./none:0 [inlined]",
      " [15] (::Main.NN.Conv2d)(::Array{Float32,4}) at /home/bcs/Desktop/MSc/repos/yolo-julia/nn.jl:114",
      " [16] (::Main.NN.Chain)(::Array{Float32,4}) at /home/bcs/Desktop/MSc/repos/yolo-julia/nn.jl:37 (repeats 2 times)",
      " [17] (::Main.NN.Chain)(::Array{Float32,4}, ::Array{Int64,1}; accuracy::Bool) at /home/bcs/Desktop/MSc/repos/yolo-julia/nn.jl:45",
      " [18] (::Main.NN.var\"#5#6\"{Bool,Main.NN.Chain})(::Tuple{Array{Float32,4},Array{Int64,1}}) at ./none:0",
      " [19] iterate at ./generator.jl:47 [inlined]",
      " [20] mean(::typeof(identity), ::Base.Generator{Data{Tuple{Array{Float32,N} where N,Array{Int64,N} where N}},Main.NN.var\"#5#6\"{Bool,Main.NN.Chain}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Statistics/src/Statistics.jl:76",
      " [21] mean at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Statistics/src/Statistics.jl:44 [inlined]",
      " [22] #_#4 at /home/bcs/Desktop/MSc/repos/yolo-julia/nn.jl:60 [inlined]",
      " [23] #train!#161 at ./In[76]:14 [inlined]",
      " [24] top-level scope at In[77]:27",
      " [25] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Random.seed!(13)\n",
    "\n",
    "model = NN.Chain(\n",
    "    NN.Conv2d(1, 3, 5),\n",
    "    NN.LeakyReLU(),\n",
    "    NN.Upsample2d(2),\n",
    "    NN.Dense(6912,10,identity),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "mdefs = parse_model_cfg(\"dummy.cfg\")\n",
    "layers, routes = create_modules(mdefs, 416)\n",
    "model = NN.Chain(\n",
    "    layers[1],\n",
    "    layers[2],\n",
    "    layers[3],\n",
    "    NN.Dense(12544,10,identity),\n",
    ")\n",
    "\n",
    "# Minibatches\n",
    "dtrn = minibatch(xtrn, ytrn, 200; xsize = (28,28,1,:), xtype=Knet.atype(), shuffle=true);\n",
    "dtst = minibatch(xtst, ytst, 200; xsize = (28,28,1,:), xtype=Knet.atype());\n",
    "\n",
    "iters, trnloss, trnacc, tstloss, tstacc = train!(\n",
    "    model, dtrn, dtst; \n",
    "    period=1, iters=16, lr=0.15, optimizer=sgd!);\n",
    "\n",
    "# @time train!(\n",
    "#     model, dtrn, dtst; \n",
    "#     period=1, iters=10, lr=0.15, optimizer=sgd!);\n",
    "\n",
    "println(\"Train loss: $(round(trnloss[end], digits=2)), Best train accuracy: $(ceil(maximum(trnacc), digits=2))\")\n",
    "println(\"Test loss: $(round(tstloss[end], digits=2)), Best test accuracy: $(ceil(maximum(tstacc), digits=2))\")\n",
    "\n",
    "plot(iters, trnloss, label=\"train\", xlabel=\"Iterations\", ylabel=\"Loss\")\n",
    "display(plot!(iters, tstloss, label=\"test\"))\n",
    "\n",
    "plot(iters, round.(1 .- trnacc, digits=2), label=\"train\", xlabel=\"Iterations\", ylabel=\"Misclassification error\")\n",
    "display(plot!(iters, round.(1 .- tstacc, digits=2), label=\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×6×1×1 Array{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       " 1.0   7.0  13.0  19.0  25.0  31.0\n",
       " 2.0   8.0  14.0  20.0  26.0  32.0\n",
       " 3.0   9.0  15.0  21.0  27.0  33.0\n",
       " 4.0  10.0  16.0  22.0  28.0  34.0\n",
       " 5.0  11.0  17.0  23.0  29.0  35.0\n",
       " 6.0  12.0  18.0  24.0  30.0  36.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = convert(Knet.atype(), reshape(1:36, (6, 6, 1, 1)))\n",
    "# y = dl2(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24×24×1×1 Array{Float32,4}:\n",
       "[:, :, 1, 1] =\n",
       " 1.0  1.0  1.0  1.0   7.0   7.0   7.0  …  25.0  25.0  31.0  31.0  31.0  31.0\n",
       " 1.0  1.0  1.0  1.0   7.0   7.0   7.0     25.0  25.0  31.0  31.0  31.0  31.0\n",
       " 1.0  1.0  1.0  1.0   7.0   7.0   7.0     25.0  25.0  31.0  31.0  31.0  31.0\n",
       " 1.0  1.0  1.0  1.0   7.0   7.0   7.0     25.0  25.0  31.0  31.0  31.0  31.0\n",
       " 2.0  2.0  2.0  2.0   8.0   8.0   8.0     26.0  26.0  32.0  32.0  32.0  32.0\n",
       " 2.0  2.0  2.0  2.0   8.0   8.0   8.0  …  26.0  26.0  32.0  32.0  32.0  32.0\n",
       " 2.0  2.0  2.0  2.0   8.0   8.0   8.0     26.0  26.0  32.0  32.0  32.0  32.0\n",
       " 2.0  2.0  2.0  2.0   8.0   8.0   8.0     26.0  26.0  32.0  32.0  32.0  32.0\n",
       " 3.0  3.0  3.0  3.0   9.0   9.0   9.0     27.0  27.0  33.0  33.0  33.0  33.0\n",
       " 3.0  3.0  3.0  3.0   9.0   9.0   9.0     27.0  27.0  33.0  33.0  33.0  33.0\n",
       " 3.0  3.0  3.0  3.0   9.0   9.0   9.0  …  27.0  27.0  33.0  33.0  33.0  33.0\n",
       " 3.0  3.0  3.0  3.0   9.0   9.0   9.0     27.0  27.0  33.0  33.0  33.0  33.0\n",
       " 4.0  4.0  4.0  4.0  10.0  10.0  10.0     28.0  28.0  34.0  34.0  34.0  34.0\n",
       " 4.0  4.0  4.0  4.0  10.0  10.0  10.0     28.0  28.0  34.0  34.0  34.0  34.0\n",
       " 4.0  4.0  4.0  4.0  10.0  10.0  10.0     28.0  28.0  34.0  34.0  34.0  34.0\n",
       " 4.0  4.0  4.0  4.0  10.0  10.0  10.0  …  28.0  28.0  34.0  34.0  34.0  34.0\n",
       " 5.0  5.0  5.0  5.0  11.0  11.0  11.0     29.0  29.0  35.0  35.0  35.0  35.0\n",
       " 5.0  5.0  5.0  5.0  11.0  11.0  11.0     29.0  29.0  35.0  35.0  35.0  35.0\n",
       " 5.0  5.0  5.0  5.0  11.0  11.0  11.0     29.0  29.0  35.0  35.0  35.0  35.0\n",
       " 5.0  5.0  5.0  5.0  11.0  11.0  11.0     29.0  29.0  35.0  35.0  35.0  35.0\n",
       " 6.0  6.0  6.0  6.0  12.0  12.0  12.0  …  30.0  30.0  36.0  36.0  36.0  36.0\n",
       " 6.0  6.0  6.0  6.0  12.0  12.0  12.0     30.0  30.0  36.0  36.0  36.0  36.0\n",
       " 6.0  6.0  6.0  6.0  12.0  12.0  12.0     30.0  30.0  36.0  36.0  36.0  36.0\n",
       " 6.0  6.0  6.0  6.0  12.0  12.0  12.0     30.0  30.0  36.0  36.0  36.0  36.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpool(xx; window=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
